{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4402b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.aggregate_results import collect_experiment_results\n",
    "from src.analysis.visualiser import ResultsVisualiser\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)        # pokazuj wszystkie kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80796ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_experiment_results('results_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedec43d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4dc34f",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ac66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = ResultsVisualiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772528f",
   "metadata": {},
   "source": [
    "## CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d209da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl = df[df['task'] == 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b1b85",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f776ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_cl, x='delta_accuracy', y='dataset', hue='missing_frac', plot_type='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7918cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[(df_cl['dataset'] == 'phoneme') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_boxplot(df_temp, x='delta_auc', y='imputer', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ad889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[(df_cl['dataset'] == 'loan') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_boxplot(df_temp, x='delta_auc', y='imputer', hue='missing_frac')\n",
    "df_temp = df_cl[(df_cl['dataset'] == 'sensors') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_boxplot(df_temp, x='delta_auc', y='imputer', hue='missing_frac')\n",
    "df_temp = df_cl[(df_cl['dataset'] == 'diabetes') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_boxplot(df_temp, x='delta_auc', y='imputer', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[(df_cl['dataset'] == 'phoneme') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_scatter(df_temp, x='imputer_rmse', y='delta_accuracy', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f19d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[(df_cl['dataset'] == 'loan') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_scatter(df_temp, x='imputer_rmse', y='delta_accuracy', hue='imputer', style='model')\n",
    "df_temp = df_cl[(df_cl['dataset'] == 'diabetes') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_scatter(df_temp, x='imputer_rmse', y='delta_accuracy', hue='imputer', style='model')\n",
    "df_temp = df_cl[(df_cl['dataset'] == 'sensors') & (df_cl['imputer'] != 'original')]\n",
    "vis.plot_scatter(df_temp, x='imputer_rmse', y='delta_accuracy', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac78e0",
   "metadata": {},
   "source": [
    "### XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa86759",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_boxplot(df_cl, x='shap_rmse_overall', y='dataset', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['dataset'] =='loan']\n",
    "vis.plot_scatter(df_temp, x='shap_rmse_overall', y='delta_accuracy', hue='imputer', style='model', figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['dataset'] =='sensors']\n",
    "vis.plot_scatter(df_temp, x='shap_rmse_overall', y='delta_accuracy', hue='imputer', style='model')\n",
    "df_temp = df_cl[df_cl['dataset'] =='diabetes']\n",
    "vis.plot_scatter(df_temp, x='shap_rmse_overall', y='delta_accuracy', hue='imputer', style='model')\n",
    "df_temp = df_cl[df_cl['dataset'] =='phoneme']\n",
    "vis.plot_scatter(df_temp, x='shap_rmse_overall', y='delta_accuracy', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863434ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] == 'xgboost']\n",
    "vis.plot_heatmap(df_temp, x='imputer', y='missing_frac', metric='shap_rmse_overall', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eabca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] == 'logistic_regression']\n",
    "vis.plot_heatmap(df_temp, x='imputer', y='missing_frac', metric='shap_rmse_overall', aggfunc='mean')\n",
    "\n",
    "df_temp = df_cl[df_cl['model'] == 'random_forest']\n",
    "vis.plot_heatmap(df_temp, x='imputer', y='missing_frac', metric='shap_rmse_overall', aggfunc='mean')\n",
    "\n",
    "df_temp = df_cl[df_cl['model'] == 'knn']\n",
    "vis.plot_heatmap(df_temp, x='imputer', y='missing_frac', metric='shap_rmse_overall', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_feature_rank_barplot_faceted_pfi(df_cl, dataset='phoneme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37caa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_feature_rank_barplot_faceted_pfi(df_cl, dataset='sensors')\n",
    "vis.plot_feature_rank_barplot_faceted_pfi(df_cl, dataset='diabetes')\n",
    "vis.plot_feature_rank_barplot_faceted_pfi(df_cl, dataset='loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] =='xgboost']\n",
    "vis.plot_boxplot(df_temp, x='pdp_aggregated', y='dataset', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88075024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] =='logistic_regression']\n",
    "vis.plot_boxplot(df_temp, x='pdp_aggregated', y='dataset', hue='missing_frac')\n",
    "df_temp = df_cl[df_cl['model'] =='knn']\n",
    "vis.plot_boxplot(df_temp, x='pdp_aggregated', y='dataset', hue='missing_frac')\n",
    "df_temp = df_cl[df_cl['model'] =='random_forest']\n",
    "vis.plot_boxplot(df_temp, x='pdp_aggregated', y='dataset', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] =='xgboost']\n",
    "vis.plot_scatter(df_temp, x='pred_rmse', y='pdp_aggregated', hue='imputer', style='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cl[df_cl['model'] =='logistic_regression']\n",
    "vis.plot_scatter(df_temp, x='pred_rmse', y='pdp_aggregated', hue='imputer', style='dataset')\n",
    "df_temp = df_cl[df_cl['model'] =='knn']\n",
    "vis.plot_scatter(df_temp, x='pred_rmse', y='pdp_aggregated', hue='imputer', style='dataset')\n",
    "df_temp = df_cl[df_cl['model'] =='random_forest']\n",
    "vis.plot_scatter(df_temp, x='pred_rmse', y='pdp_aggregated', hue='imputer', style='dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46199a9b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea589c",
   "metadata": {},
   "source": [
    "## REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75456b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = df[df['task'] == 'regression']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20b827",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6406204",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_regression, x='delta_rmse', y='dataset', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32239c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[~((df_regression['dataset'] == 'gym_excercises') & (df_regression['delta_rmse'] > 500)) & ~((df_regression['dataset'] == 'cpu') & (df_regression['delta_rmse'] > 10))]\n",
    "vis.plot_facet_grid(df_temp, x='delta_rmse', y='dataset', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[df_regression['dataset'] == 'gym_excercises']\n",
    "vis.plot_boxplot(df_temp[df_temp['imputer'] != 'original'], x='imputer_rmse', y='imputer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa34694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[df_regression['dataset'] == 'cpu']\n",
    "vis.plot_boxplot(df_temp[df_temp['imputer'] != 'original'], x='imputer_rmse', y='imputer')\n",
    "df_temp = df_regression[df_regression['dataset'] == 'concrete']\n",
    "vis.plot_boxplot(df_temp[df_temp['imputer'] != 'original'], x='imputer_rmse', y='imputer')\n",
    "df_temp = df_regression[df_regression['dataset'] == 'housing']\n",
    "vis.plot_boxplot(df_temp[df_temp['imputer'] != 'original'], x='imputer_rmse', y='imputer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[~((df_regression['dataset'] == 'gym_excercises') & (df_regression['delta_rmse'] > 500)) & ~((df_regression['dataset'] == 'cpu') & (df_regression['delta_rmse'] > 10))]\n",
    "\n",
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'cpu'], x='imputer_rmse', y='pred_rmse', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76653fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'housing'], x='imputer_rmse', y='pred_rmse', hue='missing_frac')\n",
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'gym_excercises'], x='imputer_rmse', y='pred_rmse', hue='missing_frac')\n",
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'concrete'], x='imputer_rmse', y='pred_rmse', hue='missing_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'cpu'], x='imputer_rmse', y='pred_rmse', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbe1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'concrete'], x='imputer_rmse', y='pred_rmse', hue='imputer', style='model')\n",
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'gym_excercises'], x='imputer_rmse', y='pred_rmse', hue='imputer', style='model')\n",
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'housing'], x='imputer_rmse', y='pred_rmse', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b105e",
   "metadata": {},
   "source": [
    "### XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[~((df_regression['dataset'] == 'gym_excercises') & (df_regression['shap_rmse_overall'] > 200))\n",
    "                     & ~((df_regression['dataset'] == 'cpu') & (df_regression['shap_rmse_overall'] > 10))\n",
    "                     & ~((df_regression['dataset'] == 'housing') & (df_regression['shap_rmse_overall'] > 100000))\n",
    "                     & ~((df_regression['dataset'] == 'concrete') & (df_regression['shap_rmse_overall'] > 15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_temp, x='shap_rmse_overall', y='dataset', hue='missing_frac', plot_type='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_regression[~((df_regression['model'] == 'linear_regression') & (df_regression['imputer'] == 'MICEImputer'))]\n",
    "vis.plot_heatmap(df_temp[df_temp['dataset'] == 'gym_excercises'], x='imputer', y='model', metric='shap_rmse_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a247a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_heatmap(df_temp[df_temp['dataset'] == 'cpu'], x='imputer', y='model', metric='shap_rmse_overall')\n",
    "vis.plot_heatmap(df_temp[df_temp['dataset'] == 'housing'], x='imputer', y='model', metric='shap_rmse_overall')\n",
    "vis.plot_heatmap(df_temp[df_temp['dataset'] == 'concrete'], x='imputer', y='model', metric='shap_rmse_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'cpu'], x='imputer_rmse', y='shap_rmse_overall', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb84e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'concrete'], x='imputer_rmse', y='shap_rmse_overall', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'gym_excercises'], x='imputer_rmse', y='shap_rmse_overall', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eae92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_scatter(df_temp[df_temp['dataset'] == 'housing'], x='imputer_rmse', y='shap_rmse_overall', hue='imputer', style='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_feature_rank_barplot_faceted_pfi(df_regression, dataset='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_feature_rank_barplot_faceted_pfi(df_regression, dataset='concrete')\n",
    "vis.plot_feature_rank_barplot_faceted_pfi(df_regression, dataset='gym_excercises')\n",
    "vis.plot_feature_rank_barplot_faceted_pfi(df_regression, dataset='housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdccc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_regression, x='pdp_aggregated', y='dataset', hue='missing_frac', plot_type='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_regression[~((df_regression['dataset'] == 'cpu') & (df_regression['pdp_aggregated'] < 0.75))\n",
    "#                      & ~((df_regression['dataset'] == 'gym_excercises') & (df_regression['pdp_aggregated'] < 0.75))\n",
    "#                      & ~((df_regression['dataset'] == 'housing') & (df_regression['pdp_aggregated'] < 0.75))\n",
    "#                      & ~((df_regression['dataset'] == 'concrete') & (df_regression['pdp_aggregated'] < 0.75))]   \n",
    "\n",
    "# vis.plot_facet_grid(df_temp, x='pdp_aggregated', y='dataset', hue='missing_frac', plot_type='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ccf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_regression[df_regression['dataset'] == 'concrete'], x='imputer', y='model', hue='pdp_aggregated', plot_type='heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c342db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_facet_grid(df_regression[df_regression['dataset'] == 'cpu'], x='imputer', y='model', hue='pdp_aggregated', plot_type='heatmap')\n",
    "vis.plot_facet_grid(df_regression[df_regression['dataset'] == 'gym_excercises'], x='imputer', y='model', hue='pdp_aggregated', plot_type='heatmap')\n",
    "vis.plot_facet_grid(df_regression[df_regression['dataset'] == 'housing'], x='imputer', y='model', hue='pdp_aggregated', plot_type='heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7357ab",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cfe2d",
   "metadata": {},
   "source": [
    "# PART II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87012dcb",
   "metadata": {},
   "source": [
    "## CASE I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[(df['dataset'] == 'housing') & df['model'].isin(['linear_regression', 'xgboost']) & (df['missing_frac'] != 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = df_f.groupby(['dataset', 'model', 'missing_frac', 'imputer'])[['model_rmse', 'imputer_rmse', 'pred_rmse']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e56a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_all/results_33/housing/50/xgboost/evaluation_original.pkl', 'rb') as file:\n",
    "    data_ori = pickle.load(file)\n",
    "    pd_ori = data_ori['pdp']\n",
    "\n",
    "with open('results_all/results_33/housing/50/xgboost/evaluation_kNNImputer.pkl', 'rb') as file:\n",
    "    data_knn = pickle.load(file)\n",
    "    pd_knn = data_knn['pdp']\n",
    "\n",
    "with open('results_all/results_33/housing/50/xgboost/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    data_mice = pickle.load(file)\n",
    "    pd_mice = data_mice['pdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.visualiser import ResultsVisualiser\n",
    "vis = ResultsVisualiser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39945f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot_multiple_pdp_curves([pd_ori, pd_knn, pd_mice], feature='sqft_living',\n",
    "                             labels=['Original', 'kNNImputer', 'MICEImputer'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_all/results_33/housing/50/linear_regression/evaluation_original.pkl', 'rb') as file:\n",
    "    data_ori = pickle.load(file)\n",
    "    pd_ori = data_ori['pdp']\n",
    "\n",
    "with open('results_all/results_33/housing/50/linear_regression/evaluation_kNNImputer.pkl', 'rb') as file:\n",
    "    data_knn = pickle.load(file)\n",
    "    pd_knn = data_knn['pdp']\n",
    "\n",
    "with open('results_all/results_33/housing/50/linear_regression/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    data_mice = pickle.load(file)\n",
    "    pd_mice = data_mice['pdp']\n",
    "\n",
    "vis.plot_multiple_pdp_curves([pd_ori, pd_knn, pd_mice], feature='sqft_living',\n",
    "                             labels=['Original', 'kNNImputer', 'MICEImputer'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb99ee",
   "metadata": {},
   "source": [
    "## CASE II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b593fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[(df['dataset'].isin(['loan', 'phoneme', 'diabetes', 'sensors']))]\n",
    "# & df['model'].isin(['random_forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = df_f.groupby(['dataset', 'model'])[['accuracy', 'auc', 'imputer_rmse', 'pred_rmse']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc76123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[(df['dataset'].isin(['loan', 'phoneme', 'diabetes'])) & (df['model'].isin(['random_forest', 'knn'])) & (~df['imputer'].isin(['SoftImputer', 'kNNImputer', 'MeanImputer'])) & (df['missing_frac'] == 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = df_f.groupby(['dataset', 'model', 'imputer'])[['accuracy', 'auc', 'imputer_rmse', 'pred_rmse', 'shap_rmse_overall']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_importances(importance_df: pd.DataFrame, other_importance: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compares self.importance_df to another importance dataframe.\n",
    "\n",
    "        Args:\n",
    "            other_importance (pd.DataFrame): DataFrame with columns ['Feature', 'Importance']\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Merged DataFrame with differences computed.\n",
    "        \"\"\"\n",
    "        if importance_df is None:\n",
    "            raise ValueError(\"You must call compute_importance() first!\")\n",
    "\n",
    "        # Sprawdzenie poprawności kolumn wejściowych\n",
    "        required_cols = {'Feature', 'Importance'}\n",
    "        if not required_cols.issubset(other_importance.columns):\n",
    "            raise ValueError(f\"other_importance must contain columns {required_cols}\")\n",
    "\n",
    "        # Upewnij się, że nie ma duplikatów w 'Feature'\n",
    "        if other_importance['Feature'].duplicated().any() or importance_df['Feature'].duplicated().any():\n",
    "            raise ValueError(\"Duplicate feature names found in importance DataFrames!\")\n",
    "\n",
    "        # Normalizacja nazw kolumn (np. usunięcie białych znaków)\n",
    "        self_df = importance_df.copy()\n",
    "        other_df = other_importance.copy()\n",
    "\n",
    "        # Scalanie z uwzględnieniem brakujących cech\n",
    "        merged = pd.merge(\n",
    "            self_df,\n",
    "            other_df,\n",
    "            on=\"Feature\",\n",
    "            suffixes=('_self', '_other'),\n",
    "            how=\"inner\"  # lub \"outer\", jeśli chcesz widzieć różnice w pokryciu\n",
    "        )\n",
    "\n",
    "        merged['Difference'] = merged['Importance_other'] - merged['Importance_self']\n",
    "        return merged.sort_values(by='Difference', ascending=False).reset_index(drop=True)\n",
    "\n",
    "def plot_difference(diff_df: pd.DataFrame) -> plt.Figure:\n",
    "        \"\"\"Plots difference in feature importance between two models.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        colors = ['green' if x > 0 else 'red' for x in diff_df['Difference']]\n",
    "        ax.barh(diff_df['Feature'], diff_df['Difference'], color=colors)\n",
    "        ax.axvline(0, color='black', linestyle='--')\n",
    "        ax.set_xlabel(\"Importance Difference (Imputed - Original)\")\n",
    "        ax.set_ylabel(\"Features\")\n",
    "        ax.set_title(\"Change in Feature Importance Due to Imputation\")\n",
    "        ax.invert_yaxis()\n",
    "        fig.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16129b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_all/results_123/diabetes/50/knn/evaluation_original.pkl', 'rb') as file:\n",
    "    diabetes_knn_ori = pickle.load(file)\n",
    "    diabetes_knn_ori_importance = diabetes_knn_ori['pfi']\n",
    "\n",
    "with open('results_all/results_123/diabetes/50/knn/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    diabetes_knn_rand = pickle.load(file)\n",
    "    diabetes_knn_rand_importance = diabetes_knn_rand['pfi']\n",
    "with open('results_all/results_123/diabetes/50/knn/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    diabetes_knn_mice = pickle.load(file)\n",
    "    diabetes_knn_mice_importance = diabetes_knn_mice['pfi']\n",
    "\n",
    "with open('results_all/results_123/diabetes/50/random_forest/evaluation_original.pkl', 'rb') as file:\n",
    "    diabetes_rf_ori = pickle.load(file)\n",
    "    diabetes_rf_ori_importance = diabetes_rf_ori['pfi']\n",
    "with open('results_all/results_123/diabetes/50/random_forest/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    diabetes_rf_rand = pickle.load(file)\n",
    "    diabetes_rf_rand_importance = diabetes_rf_rand['pfi']\n",
    "\n",
    "with open('results_all/results_123/diabetes/50/random_forest/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    diabetes_rf_mice = pickle.load(file)\n",
    "    diabetes_rf_mice_importance = diabetes_rf_mice['pfi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec89b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = compare_importances(diabetes_knn_ori_importance, diabetes_knn_rand_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(diabetes_knn_ori_importance, diabetes_knn_mice_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(diabetes_rf_ori_importance, diabetes_rf_rand_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(diabetes_rf_ori_importance, diabetes_rf_mice_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_all/results_123/loan/50/knn/evaluation_original.pkl', 'rb') as file:\n",
    "    loan_knn_ori = pickle.load(file)\n",
    "    loan_knn_ori_importance = loan_knn_ori['pfi']\n",
    "\n",
    "with open('results_all/results_123/loan/50/knn/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    loan_knn_rand = pickle.load(file)\n",
    "    loan_knn_rand_importance = loan_knn_rand['pfi']\n",
    "\n",
    "with open('results_all/results_123/loan/50/knn/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    loan_knn_mice = pickle.load(file)\n",
    "    loan_knn_mice_importance = loan_knn_mice['pfi']\n",
    "with open('results_all/results_123/loan/50/random_forest/evaluation_original.pkl', 'rb') as file:\n",
    "    loan_rf_ori = pickle.load(file)\n",
    "    loan_rf_ori_importance = loan_rf_ori['pfi']\n",
    "\n",
    "with open('results_all/results_123/loan/50/random_forest/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    loan_rf_rand = pickle.load(file)\n",
    "    loan_rf_rand_importance = loan_rf_rand['pfi']\n",
    "with open('results_all/results_123/loan/50/random_forest/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    loan_rf_mice = pickle.load(file)\n",
    "    loan_rf_mice_importance = loan_rf_mice['pfi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fac2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_rf_mice['shap_compared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = compare_importances(loan_knn_ori_importance, loan_knn_rand_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(loan_knn_ori_importance, loan_knn_mice_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(loan_rf_ori_importance, loan_rf_rand_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(loan_rf_ori_importance, loan_rf_mice_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a919543",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_all/results_123/phoneme/50/knn/evaluation_original.pkl', 'rb') as file:\n",
    "    phoneme_knn_ori = pickle.load(file)\n",
    "    phoneme_knn_ori_importance = phoneme_knn_ori['pfi']\n",
    "\n",
    "with open('results_all/results_123/phoneme/50/knn/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    phoneme_knn_rand = pickle.load(file)\n",
    "    phoneme_knn_rand_importance = phoneme_knn_rand['pfi']\n",
    "with open('results_all/results_123/phoneme/50/knn/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    phoneme_knn_mice = pickle.load(file)\n",
    "    phoneme_knn_mice_importance = phoneme_knn_mice['pfi']\n",
    "with open('results_all/results_123/phoneme/50/random_forest/evaluation_original.pkl', 'rb') as file:\n",
    "    phoneme_rf_ori = pickle.load(file)\n",
    "    phoneme_rf_ori_importance = phoneme_rf_ori['pfi']\n",
    "\n",
    "with open('results_all/results_123/phoneme/50/random_forest/evaluation_RandomImputer.pkl', 'rb') as file:\n",
    "    phoneme_rf_rand = pickle.load(file)\n",
    "    phoneme_rf_rand_importance = phoneme_rf_rand['pfi']\n",
    "with open('results_all/results_123/phoneme/50/random_forest/evaluation_MICEImputer.pkl', 'rb') as file:\n",
    "    phoneme_rf_mice = pickle.load(file)\n",
    "    phoneme_rf_mice_importance = phoneme_rf_mice['pfi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b547441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com = compare_importances(phoneme_knn_ori_importance, phoneme_knn_rand_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(phoneme_knn_ori_importance, phoneme_knn_mice_importance)\n",
    "plot_difference(df_com)\n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(phoneme_rf_ori_importance, phoneme_rf_rand_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()\n",
    "\n",
    "df_com = compare_importances(phoneme_rf_ori_importance, phoneme_rf_mice_importance)\n",
    "plot_difference(df_com)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc76062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "models = ['random_forest', 'knn']\n",
    "imputers = ['RandomImputer', 'MICEImputer']\n",
    "base_dir = 'results_all/results_123'\n",
    "ratio = 50\n",
    "\n",
    "def load_shap_compared(dataset, model, imputer):\n",
    "    if imputer == 'original':\n",
    "        filename = f'evaluation_original.pkl'\n",
    "    else:\n",
    "        filename = f'evaluation_{imputer}.pkl'\n",
    "    path = f\"{base_dir}/{dataset}/{ratio}/{model}/{filename}\"\n",
    "    try:\n",
    "        with open(path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            return data.get('shap_compared', None)\n",
    "    except Exception as e:\n",
    "        print(f\"Missing or error in {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_shap_rmse_table(datasets, models, imputers):\n",
    "    rows = []\n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            # Load original for reference\n",
    "            orig = load_shap_compared(dataset, model, 'original')\n",
    "            for imputer in imputers:\n",
    "                comp = load_shap_compared(dataset, model, imputer)\n",
    "                if comp is not None and 'rmse' in comp:\n",
    "                    per_feature = comp['rmse']['per_feature']\n",
    "                    overall = comp['rmse']['overall']\n",
    "                    for feature, value in per_feature.items():\n",
    "                        rows.append({\n",
    "                            'dataset': dataset,\n",
    "                            'model': model,\n",
    "                            'imputer': imputer,\n",
    "                            'feature': feature,\n",
    "                            'rmse_diff': value,\n",
    "                            'overall_rmse_diff': overall\n",
    "                        })\n",
    "                    # Add overall row\n",
    "                    rows.append({\n",
    "                        'dataset': dataset,\n",
    "                        'model': model,\n",
    "                        'imputer': imputer,\n",
    "                        'feature': 'OVERALL',\n",
    "                        'rmse_diff': overall,\n",
    "                        'overall_rmse_diff': overall\n",
    "                    })\n",
    "\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    summary_df = summary_df[['dataset', 'model', 'imputer', 'feature', 'rmse_diff', 'overall_rmse_diff']]\n",
    "    pivot_df = summary_df.pivot_table(index='feature', columns=['dataset', 'model', 'imputer'], values='rmse_diff')\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_shap_rmse_table(['loan'], models, imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_shap_rmse_table(['diabetes'], models, imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_shap_rmse_table(['phoneme'], models, imputers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.pdp_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ce921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate PDP L2 distances from df_f['pdp_compared']\n",
    "def create_pdp_l2_table(df: pd.DataFrame, dataset) -> pd.DataFrame:\n",
    "    df_f = df[df['dataset'] == dataset]\n",
    "    import numpy as np\n",
    "    pdp_rows = []\n",
    "    for idx, row in df_f.iterrows():\n",
    "        pdp_dict = row['pdp_compared']\n",
    "        if isinstance(pdp_dict, dict):\n",
    "            dataset = row['dataset']\n",
    "            model = row['model']\n",
    "            imputer = row['imputer']\n",
    "            for feature, l2_dist in pdp_dict.items():\n",
    "                pdp_rows.append({\n",
    "                    'dataset': dataset,\n",
    "                    'model': model,\n",
    "                    'imputer': imputer,\n",
    "                    'feature': feature,\n",
    "                    'l2_dist': l2_dist\n",
    "                })\n",
    "            # Add overall average for this row\n",
    "            avg_l2 = np.mean(list(pdp_dict.values()))\n",
    "            pdp_rows.append({\n",
    "                'dataset': dataset,\n",
    "                'model': model,\n",
    "                'imputer': imputer,\n",
    "                'feature': 'OVERALL',\n",
    "                'l2_dist': avg_l2\n",
    "            })\n",
    "\n",
    "    pdp_df = pd.DataFrame(pdp_rows)\n",
    "    pdp_pivot = pdp_df.pivot_table(index='feature', columns=['dataset', 'model', 'imputer'], values='l2_dist')\n",
    "    return pdp_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60caa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_l2_table(df_f, 'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_l2_table(df_f, 'loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_l2_table(df_f, 'phoneme')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b537b087",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca3e51",
   "metadata": {},
   "source": [
    "## CASE III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = ResultsVisualiser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[\n",
    "    ((df['dataset'] == 'gym_excercises') & (df['shap_rmse_overall'] > 6000)) |\n",
    "    ((df['dataset'] == 'cpu') & (df['shap_rmse_overall'] > 50000)) |\n",
    "   # ((df['dataset'] == 'housing') & (df['shap_rmse_overall'] > 100000)) |\n",
    "    ((df['dataset'] == 'concrete') & (df['shap_rmse_overall'] > 50))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2 = df[((df['dataset'] == 'cpu') & (df['imputer'] == 'original') &  (df['model'] == 'linear_regression')) & (df['missing_frac'] == 0.5) & (df['seed']==123)\n",
    "              | ((df['dataset'] == 'gym_excercises') & (df['imputer'] == 'original') &  (df['model'] == 'linear_regression')) & (df['missing_frac'] == 0.5) & (df['seed']==33)\n",
    "              | ((df['dataset'] == 'concrete') & (df['imputer'] == 'original') &  (df['model'] == 'linear_regression')) & (df['missing_frac'] == 0.5) & (df['seed']==987)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ae4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\n",
    "    {'dataset': 'cpu', 'seed': 123, 'missing_frac': 0.5, 'model': 'linear_regression'},\n",
    "    {'dataset': 'gym_excercises', 'seed': 33, 'missing_frac': 0.5, 'model': 'linear_regression'},\n",
    "    {'dataset': 'concrete', 'seed': 987, 'missing_frac': 0.5, 'model': 'linear_regression'},\n",
    "]\n",
    "\n",
    "# Find rows matching each case and get the one with the lowest shap_rmse_overall\n",
    "lowest_shap_rows = []\n",
    "for case in cases:\n",
    "    subset = df[\n",
    "        (df['dataset'] == case['dataset']) &\n",
    "        (df['seed'] == case['seed']) &\n",
    "        (df['missing_frac'] == case['missing_frac']) &\n",
    "        (df['model'] == case['model'])\n",
    "    ]\n",
    "    if not subset.empty:\n",
    "        min_row = subset.loc[subset['shap_rmse_overall'].idxmin()]\n",
    "        lowest_shap_rows.append(min_row)\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "df_lowest_shap = pd.DataFrame(lowest_shap_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_temp.columns:\n",
    "#     if df_temp[col].apply(lambda x: isinstance(x, list)).any():\n",
    "#         df_temp[col] = df_temp[col].apply(str)\n",
    "# for col in df_temp2.columns:\n",
    "#     if df_temp2[col].apply(lambda x: isinstance(x, list)).any():\n",
    "#         df_temp2[col] = df_temp2[col].apply(str)\n",
    "\n",
    "df_finish = pd.concat([df_temp, df_temp2, df_lowest_shap]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c112475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish['model_rmse'] = df_finish['model_rmse'].apply(lambda x: f\"{float(x):.4f}\")\n",
    "df_finish['pred_rmse'] = df_finish['pred_rmse'].apply(lambda x: f\"{float(x):.4f}\")\n",
    "df_finish = df_finish[['seed', 'dataset', 'model', 'imputer', 'missing_frac', 'model_rmse', 'imputer_rmse', 'pred_rmse', 'shap_rmse_overall', 'result_path']].sort_values(by='dataset').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa460558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3942c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLACE FOR SHAP FI PLOTS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish['result_path'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dataset'] == 'cpu']['pdp_compared'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147186c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_finish['result_path'].iloc[3], 'rb') as file:\n",
    "    data_bad = pickle.load(file)\n",
    "    pd_bad = data_bad['pdp']\n",
    "\n",
    "with open(df_finish['result_path'].iloc[4], 'rb') as file:\n",
    "    data_ori = pickle.load(file)\n",
    "    pd_ori = data_ori['pdp']\n",
    "\n",
    "with open(df_finish['result_path'].iloc[5], 'rb') as file:\n",
    "    data_good = pickle.load(file)\n",
    "    pd_good = data_good['pdp']\n",
    "\n",
    "vis.plot_multiple_pdp_curves([pd_ori, pd_bad, pd_good], feature='freeswap',\n",
    "                             labels=['Original', 'Bad Case - MICE', 'Good Case - Mean'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce902d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_good = data_good['shap']\n",
    "shap_bad = data_bad['shap']\n",
    "shap_ori = data_ori['shap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ea4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu = pd.read_csv('datasets/cpu.csv')\n",
    "df_cpu.drop('usr', axis=1, inplace=True)\n",
    "feature_names = df_cpu.columns.to_list()\n",
    "\n",
    "def plot_shap_waterfall(shaps, index):\n",
    "    print(\"feature_names:\", len(feature_names))\n",
    "    print(\"shaps.data shape:\", shaps.data.shape)\n",
    "    print(\"shaps.values shape:\", shaps.values.shape)\n",
    "    base_values = shaps.base_values\n",
    "    # If base_values is 2D (e.g., shape (n_samples, 2)), take the first column\n",
    "    if hasattr(base_values, 'ndim') and base_values.ndim == 2:\n",
    "        base_values = base_values[:, 0]\n",
    "    expl = shap.Explanation(\n",
    "        values=shaps.values,\n",
    "        base_values=base_values,\n",
    "        data=shaps.data,\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "    fig = shap.plots.waterfall(expl[index], show=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_waterfall(shap_ori, index=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceac99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_waterfall(shap_bad, index=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[((df['dataset'] == 'phoneme') & (df['imputer'].isin(['original', 'MeanImputer'])) & (df['model'] == 'xgboost') & (df['missing_frac'] == 0.5) & (df['seed']==42))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_best = df[\n",
    "    (df['dataset'] == 'phoneme') &\n",
    "    (df['imputer'].isin(['MeanImputer'])) &\n",
    "    (df['missing_frac'] == 0.5) &\n",
    "    (df['seed'] == 42)\n",
    "]\n",
    "\n",
    "best_row = df_temp_best.loc[(df_temp_best['model'] == 'random_forest')]# & (df_temp_best['shap_rmse_overall'].idxmin())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b21ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.concat([df_temp, best_row], ignore_index=True)\n",
    "df_finish = df_temp[['seed', 'dataset', 'model', 'imputer', 'missing_frac', 'accuracy', 'imputer_rmse', 'pred_rmse', 'shap_rmse_overall', 'pdp_aggregated', 'result_path']].sort_values(by='dataset').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_finish['result_path'].iloc[0], 'rb') as file:\n",
    "    data_ori = pickle.load(file)\n",
    "    pd_ori = data_ori['pdp']\n",
    "\n",
    "with open(df_finish['result_path'].iloc[1], 'rb') as file:\n",
    "    data_bad = pickle.load(file)\n",
    "    pd_bad = data_bad['pdp']\n",
    "\n",
    "with open(df_finish['result_path'].iloc[2], 'rb') as file:\n",
    "    data_good = pickle.load(file)\n",
    "    pd_good = data_good['pdp']\n",
    "\n",
    "vis.plot_multiple_pdp_curves([pd_ori, pd_bad, pd_good], feature='V4',\n",
    "                             labels=['Original', 'Bad Case - xgboost', 'Good Case - random forest'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phoneme = pd.read_csv('datasets/phoneme.csv')\n",
    "df_phoneme.drop('Class', axis=1, inplace=True)\n",
    "feature_names = df_phoneme.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_good = data_good['shap']\n",
    "shap_bad = data_bad['shap']\n",
    "shap_ori = data_ori['shap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ba010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_waterfall(shaps, index):\n",
    "    base_values = shaps.base_values\n",
    "    # If base_values is 2D (e.g., shape (n_samples, 2)), take the first column\n",
    "    if hasattr(base_values, 'ndim') and base_values.ndim == 2:\n",
    "        base_values = base_values[:, 0]\n",
    "    expl = shap.Explanation(\n",
    "        values=shaps.values,\n",
    "        base_values=base_values,\n",
    "        data=shaps.data,\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "    fig = shap.plots.waterfall(expl[index], show=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=137\n",
    "plot_shap_waterfall(shap_ori, index=index)\n",
    "plot_shap_waterfall(shap_bad, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d48e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
